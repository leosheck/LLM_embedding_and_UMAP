{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52f53369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ollama\n",
    "import chromadb\n",
    "\n",
    "from pylab import rcParams\n",
    "\n",
    "rcParams['figure.figsize'] = 15, 10\n",
    "rcParams['font.size'] = 20\n",
    "rcParams['axes.facecolor'] = 'white'\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac40a08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter pkl filename without pkl: myopic_maculopathy\n"
     ]
    }
   ],
   "source": [
    "filename = input('enter pkl filename without pkl: ')\n",
    "data_df = pd.read_pickle(filename + '.pkl')\n",
    "\n",
    "client = chromadb.Client()\n",
    "#name = keyword.replace(' ', '_')\n",
    "#collection = client.delete_collection(name = filename)\n",
    "collection = client.create_collection(name = filename)\n",
    "\n",
    "for i in range(len(data_df)):\n",
    "    if type(data_df['abstract_embeddings'].iloc[i]) != type(None):\n",
    "        collection.add(\n",
    "            ids= [str(i)],\n",
    "            embeddings= list(data_df['abstract_embeddings'].iloc[i]),\n",
    "            documents= ['journal:\\n' + str(data_df['journal'].iloc[i]) + '\\nyear:\\n' + str(data_df['year'].iloc[i]) + '\\nabstract:\\n' + data_df['abstract'].iloc[i]],\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2073e286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What do you want this model to output: how to treat myopic neovascular membrane?\n",
      "What role do you want this model to play? (ophthalmologist, researcher, student, etc): ophthalmologist\n",
      "**Treatment of Myopic Neovascular Membrane (MNV)**\n",
      "\n",
      "Myopic neovascular membrane (MNV) is a common complication of pathological myopia, characterized by the growth of new blood vessels in the choroid. The treatment options for MNV have evolved over the years, and currently, a combination of medical and surgical approaches is used to manage this condition.\n",
      "\n",
      "**Medical Treatment**\n",
      "\n",
      "1. **Anti-Vascular Endothelial Growth Factor (VEGF) Injections**: Bevacizumab (Avastin) or ranibizumab (Lucentis) are commonly used to treat MNV. These injections can reduce the growth of new blood vessels and improve visual acuity.\n",
      "2. ********Respond to this prompt: how to treat myopic Neov?\n"
     ]
    }
   ],
   "source": [
    "# an example prompt\n",
    "prompt = input(\"What do you want this model to output: \")\n",
    "role = input('What role do you want this model to play? (ophthalmologist, researcher, student, etc): ')\n",
    "n_results = 20\n",
    "\n",
    "model = 'mxbai-embed-large'\n",
    "\n",
    "# generate an embedding for the prompt and retrieve the most relevant doc\n",
    "response = ollama.embeddings(\n",
    "  prompt=prompt,\n",
    "  model=model\n",
    ")\n",
    "\n",
    "results = collection.query(\n",
    "  query_embeddings=[response[\"embedding\"]],\n",
    "  n_results=n_results\n",
    ")\n",
    "\n",
    "data = results['documents'][0]\n",
    "\n",
    "#generate response\n",
    "data_string = ''\n",
    "for i in range(n_results):\n",
    "    data_string += data[i] + '\\n'\n",
    "\n",
    "output = ollama.generate(\n",
    "  model=\"llama3\",\n",
    "  prompt=f\"Playing the role of {role}. Using this data: {data_string}. Respond to this prompt: {prompt}\"\n",
    ")\n",
    "\n",
    "print(output['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "798cc1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want further editing of this article? If so, what role should the editing be (e.g. content editor, SEO editor, etc)? Enter the role here, or * to quit: *\n"
     ]
    }
   ],
   "source": [
    "editing = input('Do you want further editing of this article? If so, what role should the editing be (e.g. content editor, SEO editor, etc)? Enter the role here, or * to quit: ')\n",
    "\n",
    "while (editing != '*'):\n",
    "    output = ollama.generate(\n",
    "      model=\"llama3\",\n",
    "      prompt=f\"Playing the role of {editing}, re-write this article: {output['response']}\"\n",
    "        )\n",
    "    print(output['response'])\n",
    "    editing = input('Do you want further editing of this article? If so, what role should the editing be (e.g. content editor, SEO editor, etc)? Enter the role here, or * to quit: ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5fd7f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
